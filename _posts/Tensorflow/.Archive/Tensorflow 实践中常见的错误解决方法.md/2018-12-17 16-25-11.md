### 1、ValueError: setting an array element with a sequence.
解决：这个错误通常是由于train_x,train_y 和 mask（test_x,test_y,mask）出现了问题。这个时候可以尝试打印部分train_x,部分train_y或mask。尤其注意他们的长度信息是否对应。遇到过的出错有：
```
X_train, X_test, y_train, y_test = train_test_split(data_x, data_x,test_size=0.2, random_state=4)
```
这里的train_y写错了。写成了data_x
### 2、当在tensorflow中平行的定义两张子图时报如下错误（这里定义两张子图的目的是为了在同一份代码中同时实现训练和测试，并可以在tensorflow中实现交叉验证）
```
ValueError: Variable bidirectional_rnn/fw/lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?Originally defined at:
```
解决：将两张图的初始化定义在交叉验证的循环内，代码如下：
```python
    for train_index,test_index in kf.split(data_x):
        g1 = tf.Graph()
        g2 = tf.Graph()
```
### 3、ValueError: Initializer type 'dtype: 'float64'' and explicit dtype 'dtype: 'float32'' don't match.}
解决：当用embedding_lookup（）时候遇到该问题是载入的词向量数据类型不对。通常在load_embedding()函数中将载入的词向量转成np.float32类型
### 4、InvalidArgumentError (see above for traceback): indices[1,4,0] = 78 is not in [0, 21)
```
[[Node: Train/model/embedding_lookup_1 = Gather[Tindices=DT_INT64, Tparams=DT_FLOAT, _class=["loc:@model/position_embed"], validate_indices=true, _device="/job:localhost/replica:0/task:0/device:CPU:0"](model/position_embed/read, IteratorGetNext:2)]]
```
解决：这个是由于初始化生成的词向量不够embedding_lookup去索引，因此此时检查position_embed的大小是否正确。
### 5、InvalidArgumentError (see above for traceback): seq_lens(24) > input.dims(1)
```
[[node crf_loss/ReverseSequence (defined at D:\Anaconda3\lib\site-packages\tensorflow\contrib\crf\python\ops\crf.py:562)  = ReverseSequence[T=DT_INT32, Tlen=DT_INT32, batch_dim=0, seq_dim=1, _device="/job:localhost/replica:0/task:0/device:CPU:0"](crf_loss/rnn_1/transpose_1/_753, crf_loss/Maximum/_755)]]
	 [[{{node crf_loss/rnn_2/while/Select_1/_825}} = _HostRecv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_939_crf_loss/rnn_2/while/Select_1", tensor_type=DT_INT32, _device="/job:localhost/replica:0/task:0/device:GPU:0"](^_cloopcrf_loss/rnn_2/while/strided_slice/_622)]]
```
解决：该问题发生在使用tf.contrib.crf.crf_decode()时由于该函数有三个必传参数，其中sequence_length参数传入出错的话会出现该问题。
检查你传入的句子长度列表是否正确，其次如果句子在预处理过程中做过截断操作，注意此时如果句子长度超出，该列表则只记录最大长度，不记录实际长度。
### 6、ImportError: /lib64/libstdc++.so.6: version `CXXABI_1.3.9' not found (required by /home/kyzhou/anaconda3/lib/python3.6/site-packages/scipy/sparse/_sparsetools.cpython-36m-x86_64-linux-gnu.so)

解决：
```
strings /usr/lib64/libstdc++.so.6 | grep 'CXXABI'
```
### 6、ValueError: as_list() is not defined on an unknown TensorShape.
解决：
该问题出现在以下代码后：
```
    dataset = tf.data.Dataset.from_tensor_slices(data_length).\
        batch(config.batch_size).map(lambda x:tf.py_func(get_encodes,
        [x["X"],x["Y"],x["seq_len"]],[tf.float32,tf.int32,tf.int32],
         name='client')).map(lambda x,y,seq:{"X":x,"Y":y,"seq_len":seq}).repeat(100)
    iterator = dataset.make_one_shot_iterator()
    # iterator = dataset.make_initializable_iterator()
    next_element = iterator.get_next()
    print(next_element["X"])
    return next_element,num_batch
```
使用py_fun后返回值缺少了shape属性，此时需要用set_shape()重新设置shape属性。
该案例中笔者直接将set_sh




